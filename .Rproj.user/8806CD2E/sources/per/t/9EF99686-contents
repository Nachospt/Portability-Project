##Captura de direcci?n URL

file.choose()
setwd()
getwd()

##Varios

Attributes()
Attr()
rbind(head(), tail())
Summary() ## Descripci?n de datos de matriz o tabla

## Efficient increasing functions
#Remove unnecessary objects
rm()

# Track code time to run
start.time = Sys.time()
end.time = Sys.time()
time.taken = end.time - start.time
time.taken

# Check object disk storage
print(object.size(), units="Mb")

#colclasses argument: define the column types so R doesnt need to check whole table (useful for large tables)
read.table(M, colClasses = classes)

##Lectura de archivos
DatosPaises = read.table("PaisesProteinas.txt", header=TRUE, row.names=1, sep = "\t")
Dat = read.csv(".csv")
Dat = read.csv2(".csv") ## Comas en vez de puntos y coma
library(foreign)
Vinos=read.spss("vinos.sav", to.data.frame = TRUE)

## Save an R object
saveRDS(model, "model.rds")
my_model <- readRDS("model.rds")

## Guardado en archivos
output <- file("output_file.txt", "w")
write(x, file = output)
close(output)

## Operaciones
#Como group by de SQL
housing.sum <- aggregate(housing["Home.Value"], housing["State"], FUN=mean)

## Cancel scientific notation in print
options(scipen=999)

## Calculos sumas o medias de los elementos de una matriz
rowMeans()
rowsums()

# Unique values
uniqueN()
uniqueN(x, by = "column") # Eligiendo columna

## Une por un punto todos los factores de dos listas dando todas las combinaciones.
interaction(a,b)

## Sustituir elementos
switch(x, "Vodafone" = "#E60000", "Movistar" = "#00B6E8", "Masmovil" = "#FFE500")

#
write.csv(Results.Sample, file = "Tablita.csv",row.names=TRUE, na="")

## Exploring the functions in a package
## R provides useful ways of exploring the functions of the R packages, If, for example, we wanted to list all functions in a specific package we would use a function similar to this:
  
  lsp <- function(package, all.names = FALSE, pattern)
  {
    package <- deparse(substitute(package))
    ls(
      pos = paste("package", package, sep = ":"),
      all.names = all.names,
      pattern = pattern
    )
  }
## And then we would call it like this:
  lsp(RODBC)
  
## Get all the files of a folder
  my_files <- list.files(pattern = "\\.csv$")
  
## Read all at once
  my_data <- lapply(my_files, read.csv)
  
## Dates
  M$Date2 = as.POSIXct(strptime(M$Date, "%m/%d/%Y %I:%M:%S %p"))
  
## Vectorized functions
  do.call()
  
## Read all column classes
## With data frames it will coerce the columns to use DF as a matrix is irrelevant :/
# apply(Dat, class)

## Checking NAs
  any(is.na(Datx))
  sum(is.na(Datx))
  
## Fix plot pane problem: repit dev.off until null device = 1
  dev.off()
  plot(rnorm(50), rnorm(50))
  
## Get numeric columns
  pre.temp <- pre.temp[,sapply(pre.temp, is.numeric)]

## Apply a function to each cell of a ragged array, that is to each (non-empty) group of values given by a unique combination of the levels of certain factors. 
  tapply(ingresos,list(FactorEstado,Sex), mean)
  
## Evaluating object size
  format(object.size(DF.3), units = "MB")
  sort( sapply(ls(),function(x){object.size(get(x))}))
  sort( sapply(ls(),function(x){format(object.size(get(x)), units = "MB")}))
## An empty string takes 48 bytes: 40 bytes for metadata... 8 bytes for the string
## Memory required = no. of column * no. of rows * 8 bytes/numeric
  
## Empty space
  rm(DF.1)
  
## SVM Support vector machines
  library(e1071)
  svm_model<- svm(y ~ .,
                  data = trainset,
                  type = "C-classification",
                  kernel = "linear",
                  scale = FALSE)
  svm_model$SV
  svm_model$index
  svm_model$rho
  #compute training accuracy
  pred_train <- predict(svm_model, trainset)
  mean(pred_train == trainset$y)
  
  plot(svm_model, data = trainset)
  
  ## SVM with parameter tuning
  tune_out <-tune.svm(x = trainset[, -3], y = trainset[, 3], 
             type = "C-classification", 
             kernel = "polynomial", degree = 2, cost = 10^(-1:2), 
             gamma = c(0.1, 1, 10), coef0 = c(0.1, 1, 10))
  
## Create train-tests
  #calculate accuracy for n distinct 80/20 train/test partitions
  for (i in 1:100){ 
    iris[, "train"] <- ifelse(runif(nrow(iris))<0.8, 1, 0)
    trainColNum <- grep("train", names(iris))
    trainset <- iris[iris$train == 1, -trainColNum]
    testset <- iris[iris$train == 0, -trainColNum]
    svm_model <- svm(Species~ ., data = trainset, 
                     type = "C-classification", kernel = "linear")
    pred_test <- predict(svm_model, testset)
    accuracy[i] <- mean(pred_test == testset$Species)
  }
  
  #mean accuracy and standard deviation
  mean(accuracy) 
  sd(accuracy)
  
  ## Get function code
  debug(function)
  function()
    
  ## Do.call Usefull to feed many undetermined arguments to a function like rbind
  > allframes = lapply(1:20,function(x)read.csv(paste(x,'csv',sep='.')))
  > sapply(allframes,nrow)
  [1] 21 25 27 25 27 21 24 28 23 23 22 26 24 23 25 29 28 30 27 29
  > answer = do.call(rbind,allframes)
  > nrow(answer)
  [1] 507
  
  ## Converts a windows path to the format that works in R.
  pathPrep <- function(path = "clipboard") {
    y <- if (path == "clipboard") {
      readClipboard()
    } else {
      cat("Please enter the path:\n\n")
      readline()
    }
    x <- chartr("\\", "/", y)
    writeClipboard(x)
    return(x)
  }
  
  ## Data.table (easier and faster than operating with data frames)
  # Filtering table[i,j]
  table[3:4] # Filtering, even if it has many columns.
  table[.N] # Last row.
  table[.N-10] # Last row -10.
  table[variable == "anything"] # Subset rows by column value.
  table[variable %like% "^Madrid"]  # %like% means it contains Pattern. ^ specifies pattern must be at the beggining of the string.
  table[variable %like% "Madrid$"]  # %like% means it contains Pattern. $ specifies pattern must be at the end of the string.
  table[variable %between% c(2000, 3000)] # Between filtering. Internally optimized to run in parallel. Not like argument1 & argument2.
  table[variable %chin% c("a", "b")]  # Like %in% but internally optimized.
  table[, list(var1, name = var2)]  # You can change names. No "" needed.
  table[, .(var1, name = var2)] ## Abreviation
  table[,"var1"]  # Returns a data.table
  table[,var1]  # Returns a vector, not like list(var1)
  table[, list(meanvar1 = mean(var1))] # list() to preserve the data.table when 1 column selected.
  table[,hist(var1)]  ## you can perform calculations on the j part.
  table[, .N, by = var1]  # Nrow per group.
  table[, .N, by = .(var1 = newname1, var2)] # Nrow per group combination.Assigning new name is optional.
  table[, meanvar1 = var1][order(meanvar1)][1:3]  # Chaining. I.E: average of top 3 elements.
  table[order(var1),var1[c(1,.N)], by = var2] # Keeping first and last element of var1 numeric by var2. 
  # .SD (Subset of Data) returns all the table except the grouping column.
  table[, .SD[1], by = var1]  # I.E: this returns first row of each group.
  table[, .SD[1], by = var1, .SDcols = -c("var1", "var2")]  # .SDcols arguments Returns all columns but these ones.
  table[, newvar := .N, by = var1]  # Returns DF and adds a reference column that occupies nearly no space.
                                    # Or updates a current column by aggregation.
  table[,c("minvar", "maxvar") :=.(min(var), max(var))]  # Multiple aggregations at once.
  table[,`:=`(minvar = min(var), maxvar = max(var))]  # Another method
  
  table[, newvar := NULL]  # Delete column by reference. (There is no equivalent method for rows).
  # Creates mean column for each group, changes NAs by mean of group and removes mean_var from result.
  table[, mean_var := mean(var1), by = groupingvar}[is.na(var1), var1 := mean_var, ][mean_var := NULL]
  # Condicional statements inside j.
  table[,newvar := {if (var1 > 5) "high" else "low", by = .(var2)}] # Conditions (by is necessary)
  fread("https://bit.ly/2RkBXhV") # Import data. Guesses types.
  fread(, nrows = 1, skip = 2)
  